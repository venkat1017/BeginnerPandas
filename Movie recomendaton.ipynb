{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile='https://raw.githubusercontent.com/evertongago/hadoop/master/ml-100k/u.data'\n",
    "data=pd.read_csv(datafile,sep='\\t',header=None,names=['userID','itemID','rating','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>884182806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>881171488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>253</td>\n",
       "      <td>465</td>\n",
       "      <td>5</td>\n",
       "      <td>891628467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>305</td>\n",
       "      <td>451</td>\n",
       "      <td>3</td>\n",
       "      <td>886324817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>883603013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596\n",
       "5     298     474       4  884182806\n",
       "6     115     265       2  881171488\n",
       "7     253     465       5  891628467\n",
       "8     305     451       3  886324817\n",
       "9       6      86       3  883603013"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieInfoFile='https://raw.githubusercontent.com/evertongago/hadoop/master/ml-100k/u.item'\n",
    "movieinfo=pd.read_csv(movieInfoFile,sep='|',header=None,\n",
    "                      index_col=False,names=['itemId','title'],usecols=[0,1],encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemId</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemId              title\n",
       "0       1   Toy Story (1995)\n",
       "1       2   GoldenEye (1995)\n",
       "2       3  Four Rooms (1995)\n",
       "3       4  Get Shorty (1995)\n",
       "4       5     Copycat (1995)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.merge(data,movieinfo,left_on='itemID',right_on='itemId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>itemId</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>875747190</td>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>883888671</td>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>879138235</td>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>876503793</td>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  itemId         title\n",
       "0     196     242       3  881250949     242  Kolya (1996)\n",
       "1      63     242       3  875747190     242  Kolya (1996)\n",
       "2     226     242       5  883888671     242  Kolya (1996)\n",
       "3     154     242       3  879138235     242  Kolya (1996)\n",
       "4     306     242       5  876503793     242  Kolya (1996)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def favoriteMovies(activeUser,N):\n",
    "    topMovies=pd.DataFrame.sort_values(data[data.userID==activeUser],['rating'],ascending=[0])[:N]\n",
    "    return list(topMovies.title)\n",
    "\n",
    "\n",
    "#data[data.userID==activeUser]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Empire Strikes Back, The (1980)', 'Blade Runner (1982)', 'Wrong Trousers, The (1993)']\n"
     ]
    }
   ],
   "source": [
    "print(favoriteMovies(5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "userItemRatingMatrix=pd.pivot_table(data,values='rating',index=['userID'],columns=['itemID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>itemID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "itemID  1     2     3     4     5     6     7     8     9     10    ...   \\\n",
       "userID                                                              ...    \n",
       "1        5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...    \n",
       "2        4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...    \n",
       "3        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "4        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "5        4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "\n",
       "itemID  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "userID                                                              \n",
       "1        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5        NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userItemRatingMatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import correlation\n",
    "def similarity(user1,user2):\n",
    "    user1=np.array(user1)-np.nanmean(user1)\n",
    "    user2=np.array(user2)-np.nanmean(user2)\n",
    "    commonItemIds=[i for i in range(len(user1)) if user1[i]>0 and user2[i]>0]\n",
    "    \n",
    "    if len(commonItemIds)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        user1=np.array([user1[i] for i in commonItemIds])\n",
    "        user2=np.array([user2[i] for i in commonItemIds])\n",
    "        return correlation(user1,user2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearestNeighbourRatings(activeUser,K):\n",
    "    # This function will find the K Nearest neighbours of the active user, then \n",
    "    # use their ratings to predict the activeUsers ratings for other movies \n",
    "    similarityMatrix=pd.DataFrame(index=userItemRatingMatrix.index,\n",
    "                                  columns=['Similarity'])\n",
    "    # Creates an empty matrix whose row index is userIds, and the value will be \n",
    "    # similarity of that user to the active User\n",
    "    for i in userItemRatingMatrix.index:\n",
    "        similarityMatrix.loc[i]=similarity(userItemRatingMatrix.loc[activeUser],\n",
    "                                          userItemRatingMatrix.loc[i])\n",
    "        # Find the similarity between user i and the active user and add it to the \n",
    "        # similarityMatrix \n",
    "    similarityMatrix=pd.DataFrame.sort_values(similarityMatrix,\n",
    "                                              ['Similarity'],ascending=[0])\n",
    "    # Sort the similarity matrix in the descending order of similarity \n",
    "    nearestNeighbours=similarityMatrix[:K]\n",
    "    # The above line will give us the K Nearest neighbours \n",
    "    \n",
    "    # We'll now take the nearest neighbours and use their ratings \n",
    "    # to predict the active user's rating for every movie\n",
    "    neighbourItemRatings=userItemRatingMatrix.loc[nearestNeighbours.index]\n",
    "    # There's something clever we've done here\n",
    "    # the similarity matrix had an index which was the userId, By sorting \n",
    "    # and picking the top K rows, the nearestNeighbours dataframe now has \n",
    "    # a dataframe whose row index is the userIds of the K Nearest neighbours \n",
    "    # Using this index we can directly find the corresponding rows in the \n",
    "    # user Item rating matrix \n",
    "    predictItemRating=pd.DataFrame(index=userItemRatingMatrix.columns, columns=['Rating'])\n",
    "    # A placeholder for the predicted item ratings. It's row index is the \n",
    "    # list of itemIds which is the same as the column index of userItemRatingMatrix\n",
    "    #Let's fill this up now\n",
    "    for i in userItemRatingMatrix.columns:\n",
    "        # for each item \n",
    "        predictedRating=np.nanmean(userItemRatingMatrix.loc[activeUser])\n",
    "        # start with the average rating of the user\n",
    "        for j in neighbourItemRatings.index:\n",
    "            # for each neighbour in the neighbour list \n",
    "            if userItemRatingMatrix.loc[j,i]>0:\n",
    "                # If the neighbour has rated that item\n",
    "                # Add the rating of the neighbour for that item\n",
    "                #    adjusted by \n",
    "                #    the average rating of the neighbour \n",
    "                #    weighted by \n",
    "                #    the similarity of the neighbour to the active user\n",
    "                predictedRating += (userItemRatingMatrix.loc[j,i]\n",
    "                                    -np.nanmean(userItemRatingMatrix.loc[j]))*nearestNeighbours.loc[j,'Similarity']\n",
    "        # We are out of the loop which uses the nearest neighbours, add the \n",
    "        # rating to the predicted Rating matrix\n",
    "        predictItemRating.loc[i,'Rating']=predictedRating\n",
    "    return predictItemRating\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topNRecommendations(activeUser,N):\n",
    "    predictItemRating=nearestNeighbourRatings(activeUser,10)\n",
    "    # Use the 10 nearest neighbours to find the predicted ratings\n",
    "    moviesAlreadyWatched=list(userItemRatingMatrix.loc[activeUser]\n",
    "                              .loc[userItemRatingMatrix.loc[activeUser]>0].index)\n",
    "    # find the list of items whose ratings which are not NaN\n",
    "    predictItemRating=predictItemRating.drop(moviesAlreadyWatched)\n",
    "    topRecommendations=pd.DataFrame.sort_values(predictItemRating,\n",
    "                                                ['Rating'],ascending=[0])[:N]\n",
    "    # This will give us the list of itemIds which are the top recommendations \n",
    "    # Let's find the corresponding movie titles \n",
    "    topRecommendationTitles=(movieinfo.loc[movieinfo.itemId.isin(topRecommendations.index)])\n",
    "    return list(topRecommendationTitles.title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venka\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(um, vm) / (norm(um) * norm(vm))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Empire Strikes Back, The (1980)', 'Blade Runner (1982)', 'Wrong Trousers, The (1993)', 'Duck Soup (1933)', 'Return of the Pink Panther, The (1974)'] \n",
      " ['Truth About Cats & Dogs, The (1996)', 'Scream (1996)', 'First Wives Club, The (1996)']\n"
     ]
    }
   ],
   "source": [
    "activeUser=5\n",
    "print(favoriteMovies(activeUser,5),\"\\n\",topNRecommendations(activeUser,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "# In[30]:\n",
    "\n",
    "# Let's now use matrix factorization to do the same exercise ie\n",
    "# finding the recommendations for a user\n",
    "# The idea here is to identify some factors (these are factors which influence\n",
    "# a user'r rating). The factors are identified by decomposing the \n",
    "# user item rating matrix into a user-factor matrix and a item-factor matrix\n",
    "# Each row in the user-factor matrix maps the user onto the hidden factors\n",
    "# Each row in the product factor matrix maps the item onto the hidden factors\n",
    "# This operation will be pretty expensive because it will effectively give us \n",
    "# the factor vectors needed to find the rating of any product by any user \n",
    "# (in the  previous case we only did the computations for 1 user)\n",
    "\n",
    "def matrixFactorization(R, K, steps=10, gamma=0.001,lamda=0.02):\n",
    "    # R is the user item rating matrix \n",
    "    # K is the number of factors we will find \n",
    "    # We'll be using Stochastic Gradient descent to find the factor vectors \n",
    "    # steps, gamma and lamda are parameters the SGD will use - we'll get to them\n",
    "    # in a bit \n",
    "    N=len(R.index)# Number of users\n",
    "    M=len(R.columns) # Number of items \n",
    "    P=pd.DataFrame(np.random.rand(N,K),index=R.index)\n",
    "    # This is the user factor matrix we want to find. It will have N rows \n",
    "    # on for each user and K columns, one for each factor. We are initializing \n",
    "    # this matrix with some random numbers, then we will iteratively move towards \n",
    "    # the actual value we want to find \n",
    "    Q=pd.DataFrame(np.random.rand(M,K),index=R.columns)\n",
    "    # This is the product factor matrix we want to find. It will have M rows, \n",
    "    # one for each product/item/movie. \n",
    "    for step in range(steps):\n",
    "        # SGD will loop through the ratings in the user item rating matrix \n",
    "        # It will do this as many times as we specify (number of steps) or \n",
    "        # until the error we are minimizing reaches a certain threshold \n",
    "        for i in R.index:\n",
    "            for j in R.columns:\n",
    "                if R.loc[i,j]>0:\n",
    "                    # For each rating that exists in the training set \n",
    "                    eij=R.loc[i,j]-np.dot(P.loc[i],Q.loc[j])\n",
    "                    # This is the error for one rating \n",
    "                    # ie difference between the actual value of the rating \n",
    "                    # and the predicted value (dot product of the corresponding \n",
    "                    # user factor vector and item-factor vector)\n",
    "                    # We have an error function to minimize. \n",
    "                    # The Ps and Qs should be moved in the downward direction \n",
    "                    # of the slope of the error at the current point \n",
    "                    P.loc[i]=P.loc[i]+gamma*(eij*Q.loc[j]-lamda*P.loc[i])\n",
    "                    # Gamma is the size of the step we are taking / moving the value\n",
    "                    # of P by \n",
    "                    # The value in the brackets is the partial derivative of the \n",
    "                    # error function ie the slope. Lamda is the value of the \n",
    "                    # regularization parameter which penalizes the model for the \n",
    "                    # number of factors we are finding. \n",
    "                    Q.loc[j]=Q.loc[j]+gamma*(eij*P.loc[i]-lamda*Q.loc[j])\n",
    "        # At the end of this we have looped through all the ratings once. \n",
    "        # Let's check the value of the error function to see if we have reached \n",
    "        # the threshold at which we want to stop, else we will repeat the process\n",
    "        e=0\n",
    "        for i in R.index:\n",
    "            for j in R.columns:\n",
    "                if R.loc[i,j]>0:\n",
    "                    #Sum of squares of the errors in the rating\n",
    "                    e= e + pow(R.loc[i,j]-np.dot(P.loc[i],Q.loc[j]),2)+lamda*(pow(np.linalg.norm(P.loc[i]),2)+pow(np.linalg.norm(Q.loc[j]),2))\n",
    "        if e<0.001:\n",
    "            break\n",
    "        print(step)\n",
    "    return P,Q\n",
    "\n",
    "# Let's call this function now \n",
    "(P,Q)=matrixFactorization(userItemRatingMatrix.iloc[:100,:100],K=2,gamma=0.001,lamda=0.02, steps=100)\n",
    "# Ideally you should run this over the entire matrix for a few 1000 steps, \n",
    "# This will be pretty expensive computationally. For now lets just do it over a \n",
    "# part of the rating matrix to see how it works. We've kept the steps to 100 too. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Star Wars (1977)', 'Shawshank Redemption, The (1994)', 'Fargo (1996)']\n"
     ]
    }
   ],
   "source": [
    "activeUser=1\n",
    "predictItemRating=pd.DataFrame(np.dot(P.loc[activeUser],Q.T),index=Q.index,columns=['Rating'])\n",
    "topRecommendations=pd.DataFrame.sort_values(predictItemRating,['Rating'],ascending=[0])[:3]\n",
    "# We found the ratings of all movies by the active user and then sorted them to find the top 3 movies \n",
    "topRecommendationTitles=movieinfo.loc[movieinfo.itemId.isin(topRecommendations.index)]\n",
    "print(list(topRecommendationTitles.title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 50),\n",
       " (1, 100),\n",
       " (1, 117),\n",
       " (1, 121),\n",
       " (1, 181),\n",
       " (7, 50),\n",
       " (7, 100),\n",
       " (7, 181),\n",
       " (50, 1),\n",
       " (50, 7),\n",
       " (50, 56),\n",
       " (50, 69),\n",
       " (50, 79),\n",
       " (50, 98),\n",
       " (50, 100),\n",
       " (50, 117),\n",
       " (50, 121),\n",
       " (50, 127),\n",
       " (50, 172),\n",
       " (50, 173),\n",
       " (50, 174),\n",
       " (50, 181),\n",
       " (50, 204),\n",
       " (50, 210),\n",
       " (50, 222),\n",
       " (50, 237),\n",
       " (50, 258),\n",
       " (50, 288),\n",
       " (50, 294),\n",
       " (50, 405),\n",
       " (56, 50),\n",
       " (56, 98),\n",
       " (56, 100),\n",
       " (56, 174),\n",
       " (56, 181),\n",
       " (69, 50),\n",
       " (79, 50),\n",
       " (79, 174),\n",
       " (98, 50),\n",
       " (98, 56),\n",
       " (98, 100),\n",
       " (98, 174),\n",
       " (98, 181),\n",
       " (100, 1),\n",
       " (100, 7),\n",
       " (100, 50),\n",
       " (100, 56),\n",
       " (100, 98),\n",
       " (100, 117),\n",
       " (100, 121),\n",
       " (100, 127),\n",
       " (100, 174),\n",
       " (100, 181),\n",
       " (100, 237),\n",
       " (117, 1),\n",
       " (117, 50),\n",
       " (117, 100),\n",
       " (117, 121),\n",
       " (117, 181),\n",
       " (121, 1),\n",
       " (121, 50),\n",
       " (121, 100),\n",
       " (121, 117),\n",
       " (121, 181),\n",
       " (121, 405),\n",
       " (127, 50),\n",
       " (127, 100),\n",
       " (127, 181),\n",
       " (172, 50),\n",
       " (172, 174),\n",
       " (172, 181),\n",
       " (173, 50),\n",
       " (174, 50),\n",
       " (174, 56),\n",
       " (174, 79),\n",
       " (174, 98),\n",
       " (174, 100),\n",
       " (174, 172),\n",
       " (174, 181),\n",
       " (174, 204),\n",
       " (174, 210),\n",
       " (181, 1),\n",
       " (181, 7),\n",
       " (181, 50),\n",
       " (181, 56),\n",
       " (181, 98),\n",
       " (181, 100),\n",
       " (181, 117),\n",
       " (181, 121),\n",
       " (181, 127),\n",
       " (181, 172),\n",
       " (181, 174),\n",
       " (181, 204),\n",
       " (181, 210),\n",
       " (181, 222),\n",
       " (181, 258),\n",
       " (204, 50),\n",
       " (204, 174),\n",
       " (204, 181),\n",
       " (210, 50),\n",
       " (210, 174),\n",
       " (210, 181),\n",
       " (222, 50),\n",
       " (222, 181),\n",
       " (237, 50),\n",
       " (237, 100),\n",
       " (258, 50),\n",
       " (258, 181),\n",
       " (258, 286),\n",
       " (258, 288),\n",
       " (258, 294),\n",
       " (258, 300),\n",
       " (286, 258),\n",
       " (288, 50),\n",
       " (288, 258),\n",
       " (288, 294),\n",
       " (294, 50),\n",
       " (294, 258),\n",
       " (294, 288),\n",
       " (294, 300),\n",
       " (300, 258),\n",
       " (300, 294),\n",
       " (405, 50),\n",
       " (405, 121)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import itertools \n",
    "# This module will help us generate all permutations of movies\n",
    "# We'll use that to find the possible rules and then filter for those with \n",
    "# the required confidence\n",
    "\n",
    "allitems=[]\n",
    "\n",
    "def support(itemset):\n",
    "    userList=userItemRatingMatrix.index\n",
    "    nUsers=len(userList)\n",
    "    ratingMatrix=userItemRatingMatrix\n",
    "    for item in itemset:\n",
    "        ratingMatrix=ratingMatrix.loc[ratingMatrix.loc[:,item]>0]\n",
    "        #Subset the ratingMatrix to the set of users who have rated this item \n",
    "        userList=ratingMatrix.index\n",
    "    # After looping through all the items in the set, we are left only with the\n",
    "    # users who have rated all the items in the itemset\n",
    "    return float(len(userList))/float(nUsers)\n",
    "# Support is the proportion of all users who have watched this set of movies \n",
    "\n",
    "minsupport=0.3\n",
    "for item in list(userItemRatingMatrix.columns):\n",
    "    itemset=[item]\n",
    "    if support(itemset)>minsupport:\n",
    "        allitems.append(item)\n",
    "# We are now left only with the items which have been rated by atleast 30% of \n",
    "#the users\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "len(allitems)\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "# 47 of the movies were watched by atleast 30% of the users. From these movies\n",
    "# we'll generate rules and test again for support and confidence\n",
    "minconfidence=0.1\n",
    "assocRules=[]\n",
    "i=2\n",
    "for rule in itertools.permutations(allitems,2):\n",
    "    #Generates all possible permutations of 2 items from the remaining\n",
    "    # list of 47 movies \n",
    "    from_item=[rule[0]]\n",
    "    to_item=rule\n",
    "    # each rule is a tuple of 2 items \n",
    "    confidence=support(to_item)/support(from_item)\n",
    "    if confidence>minconfidence and support(to_item)>minsupport:\n",
    "        assocRules.append(rule)\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "# This will generate all possible 2 item rules which satisfy the support and \n",
    "# confidence constraints. \n",
    "# You can continue on and write a similar bit of code for finding 3 item rules \n",
    "# or even n item rules. At each step make sure that every rule satisfies minconfidence\n",
    "# and minsupport\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "assocRules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
